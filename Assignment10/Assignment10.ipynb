{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Assignment10.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"mount_file_id":"1NWpJdhQVrGYXC1bKnrLSH0oRJR2CujV0","authorship_tag":"ABX9TyPdNspzcRVmud0MRZMcBJBy"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"2mBHycYE_r25","colab_type":"text"},"source":["# Information\n","$Writer: Junhyuck\\ Woo$ <br>\n","$Std.ID: 20145337$<br>\n","$Assignment10:\\ Multi-label\\ classification\\ using\\ neural\\ networks\\ with\\ a\\ regularization$<br>\n","$Deadline: June\\ 4, 2020$\n","<hr>"]},{"cell_type":"markdown","metadata":{"id":"49VsnYPA_uvM","colab_type":"text"},"source":["# Library"]},{"cell_type":"code","metadata":{"id":"tWQqPiDu_a1L","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt; import numpy as np; import time"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sCdvE5Tk_xWX","colab_type":"text"},"source":["# Data"]},{"cell_type":"code","metadata":{"id":"G2rbQ_rv_xj1","colab_type":"code","colab":{}},"source":["file_data   = \"/content/drive/My Drive/Spring|2020/Machine_Learning/CAU-MachineLearning/Assignment10/mnist.csv\"\n","handle_file = open(file_data, \"r\")\n","data        = handle_file.readlines()\n","handle_file.close()\n","\n","size_row    = 28    # height of the image\n","size_col    = 28    # width of the image\n","\n","num_image   = len(data)\n","count       = 0     # count for the number of images\n","\n","#\n","# normalize the values of the input data to be [0, 1]\n","#\n","def normalize(data):\n","\n","    data_normalized = (data - min(data)) / (max(data) - min(data))\n","\n","    return(data_normalized)\n","\n","#\n","# example of distance function between two vectors x and y\n","#\n","def distance(x, y):\n","\n","    d = (x - y) ** 2\n","    s = np.sum(d)\n","    # r = np.sqrt(s)\n","\n","    return(s)\n","\n","#\n","# make a matrix each column of which represents an images in a vector form\n","#\n","list_image  = np.empty((size_row * size_col, num_image), dtype=float)\n","list_label  = np.empty(num_image, dtype=int)\n","\n","for line in data:\n","\n","    line_data   = line.split(',')\n","    label       = line_data[0]\n","    im_vector   = np.asfarray(line_data[1:])\n","    im_vector   = normalize(im_vector)\n","\n","    list_label[count]       = label\n","    list_image[:, count]    = im_vector\n","\n","    count += 1"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"us5tft_tVHaO","colab_type":"text"},"source":["# Split data as train one and test one\n","Train: [1~1000] <br>\n","Test: [1001 ~ 10000]"]},{"cell_type":"code","metadata":{"id":"vmvJTCMOUi5X","colab_type":"code","colab":{}},"source":["train_m = 6000\n","test_m = num_image - train_m\n","train_image = list_image[:,:train_m]\n","test_image = list_image[:, train_m:]\n","train_label = list_label[:train_m]\n","test_label = list_label[train_m:]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vyVoS7iqA87c","colab_type":"text"},"source":["# Neural Network Architecture\n","* input layer : 784 (+ a bias)\n","* first hidden layer : 196 (+ a bias)\n","* second hidden layer : 49 (+ a bias)\n","* output layer : 10"]},{"cell_type":"code","metadata":{"id":"gQ8Qj7CVA9kl","colab_type":"code","colab":{}},"source":["mean = 0\n","sigma = 1\n","alpha = 0.3\n","lamda = 0.3\n","node_num = [784, 196, 49, 10]\n","layer_num = len(node_num)-1\n","theta_num = 0\n","\n","network = []\n","node_t = []\n","node = []\n","for i, v in enumerate(node_num[:-1]):\n","    network.append(np.random.normal(mean, sigma, (node_num[i+1], node_num[i]+1)))\n","    node_t.append(np.zeros((node_num[i]+1, test_m)))\n","    node.append(np.zeros((node_num[i]+1, train_m)))\n","    theta_num = theta_num + (node_num[i+1] * node_num[i]+1)\n","node_t.append(np.zeros((node_num[-1], test_m)))\n","node.append(np.zeros((node_num[-1], train_m)))\n","node_t = np.array(node_t)\n","node = np.array(node)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wf14VoK2BJ_f","colab_type":"text"},"source":["# Sigmoid Function (= activation function)\n","$\\sigma(z) = \\frac{1}{1 + \\exp(-z)}$<br>\n","$\\sigma(z)' = \\sigma(z)(1 - \\sigma(z))$"]},{"cell_type":"code","metadata":{"id":"OmHQD1wNBRE3","colab_type":"code","colab":{}},"source":["def sigmoid(z):\n","    return 1/(1 + np.exp(-z))\n","\n","def sigmoid_(z_):\n","    return z_*(1-z_)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"d1GjUE5cBRQR","colab_type":"text"},"source":["# Objective Function\n","$J(\\theta) = \\frac{1}{m} \\sum_{i=1}^m \\sum_{k=0}^{9}( - l^{(i)}_k \\log( h^{(i)}_k ) - (1 - l^{(i)}_k) \\log(1 - h^{(i)}_k) )$<br>\n","$\\theta = (u, v, w)$"]},{"cell_type":"code","metadata":{"id":"CL8wxPQ5BV2B","colab_type":"code","colab":{}},"source":["def one_hot(l):\n","    new_label = np.zeros((10,len(l)))\n","    for i, v in enumerate(l):\n","        new_label[v][i] = 1\n","    return new_label\n","    \n","def j_func(network, label, size, layer_num, lamda, theta_num):\n","    loss_list = -label*np.log(network[layer_num]) - (1 - label)*np.log(1-network[layer_num])\n","    theta = 0\n","    for i, v in enumerate(range(layer_num+1)):\n","        theta = theta + np.sum(network[i]*network[i])\n","    a = np.sum(loss_list)/size\n","    b = (lamda*theta)/(2*theta_num)\n","    loss = a + b\n","    return (loss)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"StGkWcXNBWIN","colab_type":"text"},"source":["# Gradient Descent (Back-propagation)"]},{"cell_type":"code","metadata":{"id":"7NxZdPBdBWTw","colab_type":"code","colab":{}},"source":["def prop(model, nodes, bias, data):\n","\n","    node = np.concatenate((bias, data), axis=0)\n","    nodes[0] = node\n","    \n","    for i, v in enumerate(node_num[1:]):\n","        node = np.dot(model[i], nodes[i])\n","        node = sigmoid(node)\n","        if v == node_num[-1]:\n","            nodes[i+1] = node\n","        else:\n","            nodes[i+1] = np.concatenate((bias, node), axis=0)\n","\n","    return nodes\n","\n","def backprop(model, node, l, size, layer_num, alpha, lamda, theta_num):\n","    new_model = model\n","\n","    tmp = (node[layer_num] - l)/size\n","    new_model[layer_num-1] = (1-alpha*lamda/theta_num)*new_model[layer_num-1] \\\n","                              - alpha*np.dot(tmp, node[layer_num-1].T)\n","\n","    for i, v in enumerate(range(layer_num-1, 0, -1)):\n","        tmp = np.dot(new_model[v].T[1:,:], tmp) * sigmoid_(node[v][1:])\n","        new_model[v-1] = new_model[v-1] - alpha * np.dot(tmp, node[v-1].T)\n","\n","    return new_model"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Yodx47E0BahM","colab_type":"text"},"source":["# Optimization"]},{"cell_type":"code","metadata":{"id":"ElrBCaopBZ9k","colab_type":"code","colab":{}},"source":["# Varibales\n","count = 1\n","accuracy_history = [[], []]\n","j = [0, 0]\n","j_old = 10\n","j_history = [[], []]\n","bias_train = np.array([np.ones(train_m)])\n","bias_test = np.array([np.ones(test_m)])\n","train_oh_label = one_hot(train_label)\n","test_oh_label = one_hot(test_label)\n","\n","# Check the runtime\n","start = time.time()\n","\n","while (abs(j_old - j[0]) > 0.002):\n","    # Reset the variables\n","    accuracy = [0, 0]\n","    \n","    # Update the Loss\n","    j_old = j[0]\n","\n","    # Train\n","    # Forward propagation\n","    node = prop(network, node, bias_train, train_image)\n","\n","    # Train Loss\n","    j[0] = j_func(node, train_oh_label, train_m, layer_num, lamda, theta_num)\n","\n","    # Train Accuracy\n","    h_argmax = []\n","    for i, v in enumerate(node[layer_num].T):\n","        h_argmax.append(np.argmax(v))\n","    accuracy[0] = np.sum(1*np.equal(h_argmax, train_label))\n","\n","    # Test\n","    # Forward propagation\n","    node_t = prop(network, node_t, bias_test, test_image)\n","\n","    # Test Loss\n","    j[1] = j_func(node_t, test_oh_label, test_m, layer_num, lamda, theta_num)\n","    \n","    # Test Accuracy\n","    h_t_argmax = []\n","    for i, v in enumerate(node_t[layer_num].T):\n","        h_t_argmax.append(np.argmax(v))\n","    accuracy[1] = np.sum(1*np.equal(h_t_argmax, test_label))\n","    \n","    # Back-propagation\n","    network = backprop(network, node, train_oh_label, train_m, layer_num, alpha, lamda, theta_num)\n","      \n","    # Record the history\n","    accuracy_history[0].append((accuracy[0]*100 / len(h_argmax)))\n","    j_history[0].append(j[0])\n","    accuracy_history[1].append(accuracy[1]*100 / len(h_t_argmax))\n","    j_history[1].append(j[1])\n","\n","    # Count Iteration\n","    count = count + 1\n","\n","runtime = int(time.time() - start)\n","minute, second = divmod(runtime, 60)\n","hour, minute = divmod(minute, 60)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uFdwGwvbEnh-","colab_type":"text"},"source":["# Check the convergence"]},{"cell_type":"code","metadata":{"id":"BVLRgBsHEnu5","colab_type":"code","colab":{}},"source":["print(\"Iteration: \", count)\n","print(\"Runtime: \", hour, \":\", minute, \":\", second)\n","print(\"Loss Diff: \", abs(j[0] - j_old))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qcSZTEkDnqwz","colab_type":"text"},"source":["# Check the history for display example"]},{"cell_type":"code","metadata":{"id":"0s0ob6EUnorb","colab_type":"code","colab":{}},"source":["classified_ex = []\n","misclassified_ex = []\n","check_list = np.zeros(10)\n","for i, v in enumerate(h_t_argmax):\n","    if v==test_label[i]:\n","        if (len(classified_ex)==10):\n","            continue\n","        else:\n","            if (check_list[v]==0):\n","                classified_ex.append(i)\n","                check_list[v] = 1\n","            else:\n","                continue\n","    else:\n","        if (len(misclassified_ex)==10):\n","            continue\n","        else:\n","            misclassified_ex.append(i)\n","    if (len(classified_ex)==10) and (len(misclassified_ex)==10):\n","        break"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NHVNnj5g_7Eg","colab_type":"text"},"source":["___\n","#Result"]},{"cell_type":"markdown","metadata":{"id":"5JEpQkoIAIyz","colab_type":"text"},"source":["# 1. Loss Curve"]},{"cell_type":"code","metadata":{"id":"lxSNy3FGABGO","colab_type":"code","colab":{}},"source":["plt.figure(figsize=(15,9))\n","plt.plot(j_history[0], color='blue', label='Train Loss')\n","plt.plot(j_history[1], color='red', label='Test Loss')\n","plt.grid()\n","plt.legend()\n","plt.title('Loss Curve', fontsize=40)\n","plt.xlabel('Iteration', fontsize=20)\n","plt.ylabel('Error', fontsize=20)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yzd5UyqfALi9","colab_type":"text"},"source":["# 2. Accuravy Curve"]},{"cell_type":"code","metadata":{"id":"SyThh7d9AL-H","colab_type":"code","colab":{}},"source":["plt.figure(figsize=(15,9))\n","plt.plot(accuracy_history[0], color='blue', label='Train Accuracy (%)')\n","plt.plot(accuracy_history[1], color='red', label='Test Accuracy (%)')\n","plt.grid()\n","plt.legend()\n","plt.title('Accuracy Curve', fontsize=40)\n","plt.xlabel('Iteration', fontsize=20)\n","plt.ylabel('Accuracy', fontsize=20)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6mbx91wOAirT","colab_type":"text"},"source":["# 3. Accuracy Value"]},{"cell_type":"code","metadata":{"id":"XuRr7I_YAl6_","colab_type":"code","colab":{}},"source":["print('Final Accuracy')\n","print('Train: %lf' %((accuracy[0]*100 / len(h_argmax))))\n","print('Test: %lf' %((accuracy[1]*100 / len(h_t_argmax))))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EPJgkP8_AoYx","colab_type":"text"},"source":["# 4. Classification Example\n","## 1. Correctly Classified Testing Image"]},{"cell_type":"code","metadata":{"id":"9qPBCb4-A1Ua","colab_type":"code","colab":{}},"source":["f1 = plt.figure(figsize=(10,6))\n","plt.suptitle(\"Correctly Classified\", fontsize = 40)\n","for i in range(10):\n","\n","    im_vector   = test_image[:, classified_ex[i]]\n","    im_matrix   = im_vector.reshape((size_row, size_col))\n","\n","    plt.subplot(2, 5, i+1)\n","    plt.title(h_t_argmax[classified_ex[i]], fontsize=20)\n","    plt.imshow(im_matrix, cmap='Greys', interpolation='None')\n","\n","    frame   = plt.gca()\n","    frame.axes.get_xaxis().set_visible(False)\n","    frame.axes.get_yaxis().set_visible(False)\n","\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XSVnfjfhkZUb","colab_type":"text"},"source":["## 2. Misclassified Testing Image"]},{"cell_type":"code","metadata":{"id":"KHk7L8RvW4lh","colab_type":"code","colab":{}},"source":["f1 = plt.figure(figsize=(10,6))\n","plt.suptitle(\"Misclassified\", fontsize = 40)\n","for i in range(10):\n","\n","    im_vector   = test_image[:, misclassified_ex[i]]\n","    im_matrix   = im_vector.reshape((size_row, size_col))\n","\n","    plt.subplot(2, 5, i+1)\n","    plt.title(h_t_argmax[misclassified_ex[i]], fontsize=20)\n","    plt.imshow(im_matrix, cmap='Greys', interpolation='None')\n","\n","    frame   = plt.gca()\n","    frame.axes.get_xaxis().set_visible(False)\n","    frame.axes.get_yaxis().set_visible(False)\n","\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"T_U6hAlzz5LZ","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}